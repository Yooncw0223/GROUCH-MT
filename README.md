
# GROUCH-MT

This project was done in group (Chaitanya Ravuri, Karissa Sanchez, Chanwoo Yoon) as a final group project for 6.8610 Natural Language Processing (ML) class at MIT during Fall 2022.

The project's aim was to identify methods with which machine translation models (specifically Transformer models) could be improved to achieve better performance and translation accuracy. Some of the methods that we experimented with includes input and output augmentation, teacher forcing, and pipelining model that is based on a larger dataset (e.g., pipelining our model's output, which is a result of translating from Spanish to English, to an English grammar-correction model that is trained with a substantially larger dataset).

Note that not all files are here as some files are still being recovered. As more are recovered, they will be pushed to this repository.

Moreover, great thanks to Francois Chollet (fchollet) who published the baseline transformer architecture.
